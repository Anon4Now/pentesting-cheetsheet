# <a id="top-of-page"></a> Active Information Gathering

### Links

- [Active Information Gathering](#a-info-gathering)
  - [Active Infrastructure Identification](#act-infra-id)
    - Manual Server Testing
    - WhatWeb
    - Wappalyzer
    - WafW00f
    - Aquatone
  - [Active Subdomain Enumeration](#act-domain-enum)
    - ZoneTransfers
    - GoBuster
  - [Virtual Hosts](#vhosts)
    - Manual vHost Discovery
    - FFuF
  - [Crawling](#crawl)
    - ZAP
    - FFuF
    - CeWL

## <a id="act-infra-id"></a> -Active Infrastructure Identification-

An attacker should collect as much information as possible from the webserver to understand its functionality, which can affect future testing. For example, URL rewriting functionality, load balancing, script engines used on the server, or an Intrusion detection system (IDS) in place may impede some testing activities.

| **Command**                  | **Description**                        |
| ---------------------------- | -------------------------------------- |
| `curl -I "http://${TARGET}"` | Get the header info from the Webserver |

There are also other characteristics to take into account while fingerprinting web servers in the response headers. These are:

X-Powered-By header: This header can ID what the web app is using. This is based on the values like PHP, ASP.NET, JSP, etc.

Cookies: Cookies are another attractive value to look at as each technology by default has its cookies. Some of the default cookie values are:

- .NET: ASPSESSIONID<RANDOM>=<COOKIE_VALUE>
- PHP: PHPSESSID=<COOKIE_VALUE>
- JAVA: JSESSION=<COOKIE_VALUE>

### --WhatWeb--

[Whatweb](https://www.morningstarsecurity.com/research/whatweb) recognizes web technologies, including content management systems (CMS), blogging platforms, statistic/analytics packages, JavaScript libraries, web servers, and embedded devices. It is recommended to read the whatweb help menu via whatweb -h to understand the available options, like the aggression level controls or verbose output.

| **Command**                               | **Description**                              |
| ----------------------------------------- | -------------------------------------------- |
| `whatweb -a3 https://www.<TARGET>.com -v` | Perform whatweb scan with aggression level 3 |

### --Wappalyzer--

Browser extension that can used to view the web technologies on the page. Similar to WhatWeb, but shown in browser.

### --WafW00F--

WafW00f is a web application firewall (WAF) fingerprinting tool that sends requests and analyses responses to determine if a security solution is in place.

| **Command**                   | **Description**                                                  |
| ----------------------------- | ---------------------------------------------------------------- |
| `sudo apt install wafw00f -y` | Install wafw00f on debain distro                                 |
| `-a`                          | Flag checking all WAFs in place instead of stopping on 1st match |
| `-i`                          | Flag to read targets from input file                             |
| `-p`                          | Flag to proxy requests                                           |

### --Aquatone--

Aquatone is a tool for automatic and visual inspection of websites across many hosts and is convenient for quickly gaining an overview of HTTP-based attack surfaces by scanning a list of configurable ports, visiting the website with a headless Chrome browser, and taking a screenshot. This is helpful, especially when dealing with huge subdomain lists.

| **Command**                                                                      | **Description**                                                        |
| -------------------------------------------------------------------------------- | ---------------------------------------------------------------------- |
| `sudo apt install golang chromium-driver`                                        | Install chrome driver for go                                           |
| `go get github.com/michenriksen/aquatone`                                        | Download module for go code                                            |
| `export PATH="$PATH":"$HOME/go/bin"`                                             | Set env var for nix                                                    |
| `cat <TARGET>_aquatone.txt \| aquatone -out ./aquatone -screenshot-timeout 1000` | Pipe list of known subdomains into aquatone so it can take screenshots |

When Aquatone finishes, it will generate a file called aquatone_report.html where we screenshots, technologies identified, server response headers, and HTML can be seen.

</br>

## <a id="act-domain-enum"></a> -Active Subdomain Enumeration-

Subdomain enumeration isa the process of probing the infrastructure managed by the target organization or the 3rd party DNS servers that have been identified. In this case, the amount of traffic generated can lead to the detection of reconnaissance activities so caution should be excercised.

### --ZoneTransfers--

The zone transfer is how a secondary DNS server receives information from the primary DNS server and updates it. The master-slave approach is used to organize DNS servers within a domain, with the slaves receiving updated DNS information from the master DNS. The master DNS server should be configured to enable zone transfers from secondary (slave) DNS servers, although this might be misconfigured.

_Automated Tools_

- [HackerTarget](https://hackertarget.com/zone-transfer/)

_Manual Tools_

**---Nslookup---**

| **Command**                                                | **Description**                                         |
| ---------------------------------------------------------- | ------------------------------------------------------- |
| `nslookup -type=NS <TARGET>.com`                           | Use Nslookup to find name servers for a domain          |
| `nslookup -type=any -query=AXFR <TARGET>.com <NAMESERVER>` | Use Nslookup to perform the zone transfer (if possible) |

**---DIG---**

| **Command**                | **Description**        |
| -------------------------- | ---------------------- |
| `dig <TARGET>.com -t axfr` | Perform a zone transer |

**---Gobuster---**

This tool can perform subdomain enumeration using patterns that have been identified in the passive info gathering phase. Using Seclists for the wordlists and a custom pattern list, Gobuster can perform a brute-force to find new subdomains.

Take for example in passive info gathering a subdomain pattern of 'lert-api-shv-{NUMBER}-sin6.<TARGET>.com' emerged, the steps below could be leveraged to find other subdomains using that pattern.

Build a file with the patterns (e.g., patterns.txt)

```
lert-api-shv-{GOBUSTER}-sin6
atlas-pp-shv-{GOBUSTER}-sin6
```

Launch gobuster using the dns module, specifying the following options:

dns: Launch the DNS module
-q: Don't print the banner and other noise.
-r: Use custom DNS server
-d: A target domain name
-p: Path to the patterns file
-w: Path to the wordlist
-o: Output file

| **Command**                                                                                                | **Description**                                  |
| ---------------------------------------------------------------------------------------------------------- | ------------------------------------------------ |
| ` export TARGET="<TARGET>.com"`                                                                            | Set env var nix                                  |
| `export NS="d.ns.facebook.com"`                                                                            | Set env var nix                                  |
| `export WORDLIST="numbers.txt"`                                                                            | Set env var nix                                  |
| `gobuster dns -q -r "${NS}" -d "${TARGET}" -w "${WORDLIST}" -p ./patterns.txt -o "gobuster_${TARGET}.txt"` | Perform subdomain enumeration using the env vars |

## --Virtual Hosts--

A virtual host (vHost) is a feature that allows several websites to be hosted on a single server.
There are two ways to configure virtual hosts:

- IP-based virtual hosting
- Name-based virtual hosting

**IP-based Virtual Hosting**

A host can have multiple network interfaces, multiple IP addresses, or interface aliases, and can be configured on each network interface of a host. The servers or virtual servers running on the host can bind to one or more IP addresses, which means that different servers can be addressed under different IP addresses on this host. From the client's point of view, the servers are independent of each other.

**Name-based Virtual Hosting**

The distinction for which domain the service was requested is made at the application level. For example, several domain names, such as admin.<TARGET>.com and backup.<TARGET>.com, can refer to the same IP. Internally on the server, these are separated and distinguished using different folders. Using this example, on a Linux server, the vHost admin.<TARGET>.com could point to the folder /var/www/admin. For backup.<TARGET>.com the folder name would then be adapted and could look something like /var/www/backup.

**_Manual Tests_**

cURL vHost Fuzzing
| **Command** | **Description** |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------- |
| `curl -s http://IP -H "Host: randomtarget.com"` | Using HOST header in the cURL request to check for vhosts |
| `cat wordlist \| while read vhost;do echo "\n********\nFUZZING: ${vhost}\n********";curl -s -I http://IP -H "HOST: ${vhost}.randomtarget.com" \| grep "Content-Length: ";done` | Use BASH to perform the VHOST fuzzing |

**_Automated Tests_**

FFuF vHost Testing

## <LINK TO THE FFUF CHEETSHEET>

## <a id="crawl"></a> --Crawling--

**---ZAP Spider---**

The steps to perform spidering are below:

1. Open ZAP, and on the top-right corner, open the browser
2. Write the website in the address bar and add it to the scope using the first entry in the left menu
3. Head back to the ZAP Window, right-click on the target website, click on the Attack menu, and then the Spider submenu
4. Once the process has finished, we can see the resources discovered by the spidering process

**---FFuF---**

FFuF can discover files and folders that cannot be spotted by simply browsing the website. All that is needed is launch ffuf with a list of folders names and instruct it to look recursively through them.

## <LINK TO THE FFUF CHEETSHEET>

**---CeWL---**

[CeWL](https://github.com/digininja/CeWL) (Custom Word List generator) is a ruby app which spiders a given URL, up to a specified depth, and returns a list of words which can then be used for password crackers such as John the Ripper. Optionally, CeWL can follow external links.

| **Command**            | **Description**                          |
| ---------------------- | ---------------------------------------- |
| `cewl http://<TARGET>` | Perform a crawl on a target              |
| `-m5`                  | Extract words with min length of 5 chars |
| `--lowercase`          | Convert found words to lowercase         |
| `-w <FILE>`            | Save output to file                      |

[Back to top](#top-of-page)
